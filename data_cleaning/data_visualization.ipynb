{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f86891a9",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Create a comprehensive revenue trend analysis showing yearly revenue growth from 2015-2025. Include percentage growth rates, trend lines, and highlight key growth periods with annotations.\n",
    "# Question 2\n",
    "Analyze seasonal patterns in sales data. Create monthly sales heatmaps and identify peak selling months. Compare seasonal trends across different years and categories.\n",
    "# Question 3\n",
    "Build a customer segmentation analysis using RFM (Recency, Frequency, Monetary) methodology. Create scatter plots and segment customers into meaningful groups with actionable insights.\n",
    "# Question 4\n",
    "Visualize the evolution of payment methods from 2015-2025. Show the rise of UPI, decline of COD, and create stacked area charts to demonstrate market share changes over time.\n",
    "# Question 5\n",
    "Perform category-wise performance analysis. Create treemaps, bar charts, and pie charts showing revenue contribution, growth rates, and market share for each product category.\n",
    "# Question 6\n",
    "Analyze Prime membership impact on customer behavior. Compare average order values, order frequency, and category preferences between Prime and non-Prime customers using multiple visualization types.\n",
    "# Question 7\n",
    "Create geographic analysis of sales performance across Indian cities and states. Build choropleth maps and bar charts showing revenue density and growth patterns by tier (Metro/Tier1/Tier2/Rural).\n",
    "# Question 8\n",
    "Study festival sales impact using before/during/after analysis. Visualize revenue spikes during Diwali, Prime Day, and other festivals with detailed time series analysis.\n",
    "# Question 9\n",
    "Analyze customer age group behavior and preferences. Create demographic analysis with category preferences, spending patterns, and shopping frequency across different age segments.\n",
    "# Question 10\n",
    "Build price vs demand analysis using scatter plots and correlation matrices. Analyze how pricing strategies affect sales volumes across different categories and customer segments.\n",
    "# Question 11\n",
    "Create delivery performance analysis showing delivery days distribution, on-time performance, and customer satisfaction correlation with delivery speed across different cities and customer tiers.\n",
    "# Question 12\n",
    "Analyze return patterns and customer satisfaction using return rates, reasons, and correlation with product ratings, prices, and categories through multiple visualization techniques.\n",
    "# Question 13\n",
    "Study brand performance and market share evolution. Create brand comparison charts, market share trends, and competitive positioning analysis across different categories.\n",
    "# Question 14\n",
    "Build customer lifetime value (CLV) analysis using cohort analysis, retention curves, and CLV distribution across different customer segments and acquisition years.\n",
    "# Question 15\n",
    "Analyze discount and promotional effectiveness. Create discount impact analysis showing correlation between discount percentages, sales volumes, and revenue across categories and time periods.\n",
    "# Question 16\n",
    "Study product rating patterns and their impact on sales. Analyze rating distributions, correlation with sales performance, and identify patterns across categories and price ranges.\n",
    "# Question 17\n",
    "Create customer journey analysis showing purchase frequency patterns, category transitions, and customer evolution from first purchase to loyal customers using flow diagrams and transition matrices.\n",
    "# Question 18\n",
    "Analyze inventory and product lifecycle patterns. Study product launch success, decline phases, and category evolution over the decade with detailed trend analysis.\n",
    "# Question 19\n",
    "Build competitive pricing analysis comparing brand positioning, price ranges, and market penetration strategies across different product categories using box plots and competitive matrices.\n",
    "# Question 20\n",
    "Create a comprehensive business health dashboard combining key metrics like revenue growth, customer acquisition, retention rates, and operational efficiency using multi-panel visualizations with executive summary insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e5c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import squarify\n",
    "from sklearn.cluster import KMeans\n",
    "from datetime import datetime\n",
    "\n",
    "# ----------------------\n",
    "# Helper Function: Load Local CSVs\n",
    "# ----------------------\n",
    "# def load_amazon_data(data_dir):\n",
    "#     import os, glob, pandas as pd\n",
    "\n",
    "#     pattern = os.path.join(data_dir, \"amazon_india_20*.csv\")\n",
    "#     all_files = sorted(glob.glob(pattern))\n",
    "#     df_list = []\n",
    "\n",
    "#     for f in all_files:\n",
    "#         try:\n",
    "#             df = pd.read_csv(f)\n",
    "#             df_list.append(df)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error reading {f}: {e}\")\n",
    "\n",
    "#     if not df_list:\n",
    "#         raise FileNotFoundError(f\"No amazon_india_20xx.csv files found in {data_dir}\")\n",
    "\n",
    "#     data = pd.concat(df_list, ignore_index=True)\n",
    "#     data.columns = [c.strip().lower() for c in data.columns]\n",
    "\n",
    "#     # Ensure order_date is datetime\n",
    "#     data[\"order_date\"] = pd.to_datetime(data[\"order_date\"], errors=\"coerce\")\n",
    "\n",
    "#     # Revenue column\n",
    "#     if \"final_amount_inr\" in data.columns:\n",
    "#         data.rename(columns={\"final_amount_inr\": \"revenue\"}, inplace=True)\n",
    "#     else:\n",
    "#         raise KeyError(\"'final_amount_inr' column missing. Available columns: \"\n",
    "#                        f\"{list(data.columns)}\")\n",
    "\n",
    "#     # Ensure order_id column exists\n",
    "#     if \"transaction_id\" in data.columns:\n",
    "#         data.rename(columns={\"transaction_id\": \"order_id\"}, inplace=True)\n",
    "#     else:\n",
    "#         raise KeyError(\"'transaction_id' column missing. Cannot derive order_id.\")\n",
    "\n",
    "#     return data\n",
    "\n",
    "def load_amazon_data(data_dir):\n",
    "    import os, glob, pandas as pd\n",
    "\n",
    "    pattern = os.path.join(data_dir, \"amazon_india_20*.csv\")\n",
    "    all_files = sorted(glob.glob(pattern))\n",
    "    df_list = []\n",
    "\n",
    "    for f in all_files:\n",
    "        try:\n",
    "            df = pd.read_csv(f)\n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {f}: {e}\")\n",
    "\n",
    "    if not df_list:\n",
    "        raise FileNotFoundError(f\"No amazon_india_20xx.csv files found in {data_dir}\")\n",
    "\n",
    "    data = pd.concat(df_list, ignore_index=True)\n",
    "    data.columns = [c.strip().lower() for c in data.columns]\n",
    "\n",
    "    # Convert order_date\n",
    "    data[\"order_date\"] = pd.to_datetime(data[\"order_date\"], errors=\"coerce\")\n",
    "\n",
    "    # Revenue column\n",
    "    if \"final_amount_inr\" in data.columns:\n",
    "        data.rename(columns={\"final_amount_inr\": \"revenue\"}, inplace=True)\n",
    "    else:\n",
    "        raise KeyError(\"'final_amount_inr' column missing. Available columns: \"\n",
    "                       f\"{list(data.columns)}\")\n",
    "\n",
    "    # Ensure order_id column exists\n",
    "    if \"transaction_id\" in data.columns:\n",
    "        data.rename(columns={\"transaction_id\": \"order_id\"}, inplace=True)\n",
    "    else:\n",
    "        raise KeyError(\"'transaction_id' column missing. Cannot derive order_id.\")\n",
    "\n",
    "    # Normalize prime membership column\n",
    "    if \"is_prime_member\" in data.columns:\n",
    "        data.rename(columns={\"is_prime_member\": \"prime_member\"}, inplace=True)\n",
    "        # Convert to boolean\n",
    "        data[\"prime_member\"] = data[\"prime_member\"].astype(bool)\n",
    "    else:\n",
    "        # If column missing, create default (all False)\n",
    "        data[\"prime_member\"] = False\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# Question 1: Revenue Trend Analysis\n",
    "# ----------------------\n",
    "def revenue_trend_analysis(df):\n",
    "    df['year'] = df['order_date'].dt.year\n",
    "    yearly_revenue = df.groupby('year')['revenue'].sum().reset_index()\n",
    "    yearly_revenue['growth_%'] = yearly_revenue['revenue'].pct_change() * 100\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(x='year', y='revenue', data=yearly_revenue, marker='o')\n",
    "    for _, row in yearly_revenue.iterrows():\n",
    "        if not pd.isna(row['growth_%']):\n",
    "            plt.text(row['year'], row['revenue'], f\"{row['growth_%']:.1f}%\", ha='center', va='bottom')\n",
    "    plt.title(\"Yearly Revenue Trend (2015-2025)\")\n",
    "    plt.ylabel(\"Revenue\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(\"outputs\", exist_ok=True)\n",
    "    plt.savefig(\"outputs/yearly_revenue_trend.png\")\n",
    "    plt.close()\n",
    "    yearly_revenue.to_csv(\"outputs/yearly_revenue_trend.csv\", index=False)\n",
    "\n",
    "# ----------------------\n",
    "# Question 2: Seasonal Pattern Analysis\n",
    "# ----------------------\n",
    "def seasonal_pattern_analysis(df):\n",
    "    df['year'] = df['order_date'].dt.year\n",
    "    df['month'] = df['order_date'].dt.month\n",
    "    monthly_sales = df.groupby(['year', 'month'])['revenue'].sum().reset_index()\n",
    "    pivot_table = monthly_sales.pivot(index='month', columns='year', values='revenue')\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(pivot_table, cmap='YlGnBu')\n",
    "    plt.title(\"Monthly Sales Heatmap\")\n",
    "    plt.savefig(\"outputs/monthly_sales_heatmap.png\")\n",
    "    plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Question 3: Customer Segmentation (RFM)\n",
    "# ----------------------\n",
    "def rfm_customer_segmentation(df):\n",
    "    # Drop rows with missing critical values\n",
    "    df = df.dropna(subset=[\"customer_id\", \"order_id\", \"order_date\", \"revenue\"])\n",
    "\n",
    "    snapshot_date = df['order_date'].max() + pd.Timedelta(days=1)\n",
    "\n",
    "    rfm = df.groupby('customer_id').agg({\n",
    "        'order_date': lambda x: (snapshot_date - x.max()).days,\n",
    "        'order_id': 'nunique',\n",
    "        'revenue': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    rfm.rename(columns={\n",
    "        'order_date': 'recency',\n",
    "        'order_id': 'frequency',\n",
    "        'revenue': 'monetary'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Remove rows with missing or zero values\n",
    "    rfm = rfm.fillna(0)\n",
    "    rfm = rfm[(rfm['monetary'] > 0) & (rfm['frequency'] > 0)]\n",
    "\n",
    "    # Normalize data before clustering\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    rfm_scaled = scaler.fit_transform(rfm[['recency', 'frequency', 'monetary']])\n",
    "\n",
    "    from sklearn.cluster import KMeans\n",
    "    kmeans = KMeans(n_clusters=4, random_state=42, n_init='auto')\n",
    "    rfm['Cluster'] = kmeans.fit_predict(rfm_scaled)\n",
    "\n",
    "    # Visualization\n",
    "    import plotly.express as px\n",
    "    fig = px.scatter_3d(\n",
    "        rfm, x='recency', y='frequency', z='monetary',\n",
    "        color='Cluster', title=\"RFM Customer Segmentation\"\n",
    "    )\n",
    "    fig.write_html(\"outputs/rfm_customer_segmentation.html\")\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# Question 4: Payment Method Evolution\n",
    "# ----------------------\n",
    "def payment_method_evolution(df):\n",
    "    df['year'] = df['order_date'].dt.year\n",
    "    payment_trend = df.groupby(['year', 'payment_method'])['order_id'].count().reset_index()\n",
    "    pivot = payment_trend.pivot(index='year', columns='payment_method', values='order_id').fillna(0)\n",
    "    pivot.plot.area(figsize=(12,6))\n",
    "    plt.title(\"Payment Method Market Share (2015-2025)\")\n",
    "    plt.ylabel(\"Number of Orders\")\n",
    "    plt.savefig(\"outputs/payment_method_evolution.png\")\n",
    "    plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Question 5: Category-wise Performance\n",
    "# ----------------------\n",
    "def category_performance(df):\n",
    "    cat_rev = df.groupby('category')['revenue'].sum().reset_index()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    squarify.plot(sizes=cat_rev['revenue'], label=cat_rev['category'], alpha=0.8)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Category Revenue Contribution Treemap\")\n",
    "    plt.savefig(\"outputs/category_treemap.png\")\n",
    "    plt.close()\n",
    "    cat_rev.sort_values('revenue').plot(kind='barh', x='category', y='revenue', figsize=(10,6))\n",
    "    plt.title(\"Category Revenue Bar Chart\")\n",
    "    plt.savefig(\"outputs/category_bar_chart.png\")\n",
    "    plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Question 6: Prime Membership Impact\n",
    "# ----------------------\n",
    "def prime_impact(df):\n",
    "    prime_stats = df.groupby('prime_member').agg({'revenue':'mean','order_id':'nunique'}).reset_index()\n",
    "    prime_stats.to_csv(\"outputs/prime_impact.csv\", index=False)\n",
    "    sns.barplot(x='prime_member', y='revenue', data=prime_stats)\n",
    "    plt.title(\"Average Order Value: Prime vs Non-Prime\")\n",
    "    plt.savefig(\"outputs/prime_vs_nonprime_aov.png\")\n",
    "    plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Question 7: Geographic Analysis\n",
    "# ----------------------\n",
    "def geographic_analysis(df):\n",
    "    city_rev = df.groupby('customer_city')['revenue'].sum().reset_index()\n",
    "    top_cities = city_rev.sort_values('revenue', ascending=False).head(20)\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.barplot(y='customer_city', x='revenue', data=top_cities)\n",
    "    plt.title(\"Top 20 Cities by Revenue\")\n",
    "    plt.savefig(\"outputs/top_cities_revenue.png\")\n",
    "    plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Question 8: Festival Impact\n",
    "# ----------------------\n",
    "def festival_impact(df, festival_dates):\n",
    "    for fest, dates in festival_dates.items():\n",
    "        mask = (df['order_date'] >= dates['start']) & (df['order_date'] <= dates['end'])\n",
    "        fest_df = df.loc[mask]\n",
    "        daily = fest_df.groupby(df['order_date'].dt.date)['revenue'].sum()\n",
    "        daily.plot(figsize=(10,4), marker='o')\n",
    "        plt.title(f\"Revenue Trend During {fest}\")\n",
    "        plt.savefig(f\"outputs/{fest}_trend.png\")\n",
    "        plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Question 9: Age Group Behavior\n",
    "# ----------------------\n",
    "def age_group_behavior(df):\n",
    "    age_rev = df.groupby('customer_age_group')['revenue'].sum().reset_index()\n",
    "    sns.barplot(x='customer_age_group', y='revenue', data=age_rev)\n",
    "    plt.title(\"Revenue by Age Group\")\n",
    "    plt.savefig(\"outputs/age_group_revenue.png\")\n",
    "    plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Question 10: Price vs Demand\n",
    "# ----------------------\n",
    "def price_vs_demand(df):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.scatter(df['subtotal_inr'], df['quantity'], alpha=0.5)\n",
    "    plt.xlabel(\"Price\")\n",
    "    plt.ylabel(\"Quantity\")\n",
    "    plt.title(\"Price vs Demand\")\n",
    "    plt.savefig(\"outputs/price_vs_demand.png\")\n",
    "    plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Question 11: Delivery Performance\n",
    "# ----------------------\n",
    "def delivery_performance(df):\n",
    "    sns.histplot(df['delivery_days'], bins=20, kde=True)\n",
    "    plt.title(\"Delivery Days Distribution\")\n",
    "    plt.savefig(\"outputs/delivery_days_distribution.png\")\n",
    "    plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Question 12: Return Patterns\n",
    "# ----------------------\n",
    "# def return_patterns(df):\n",
    "#     return_rate = df['return_status'].mean() * 100\n",
    "#     print(f\"Overall Return Rate: {return_rate:.2f}%\")\n",
    "#     sns.barplot(x='category', y='return_status', data=df)\n",
    "#     plt.xticks(rotation=90)\n",
    "#     plt.title(\"Return Rate by Category\")\n",
    "#     plt.savefig(\"outputs/return_rate_by_category.png\")\n",
    "#     plt.close()\n",
    "\n",
    "def return_patterns(df):\n",
    "    if 'return_status' not in df.columns:\n",
    "        print(\"Warning: 'return_status' column not found. Skipping return analysis.\")\n",
    "        return\n",
    "    \n",
    "    # Convert to numeric: Yes -> 1, No -> 0\n",
    "    df['return_status_numeric'] = df['return_status'].map({'Yes':1, 'No':0})\n",
    "    \n",
    "    if df['return_status_numeric'].isna().all():\n",
    "        print(\"Warning: 'return_status' column has no recognizable values.\")\n",
    "        return\n",
    "    \n",
    "    return_rate = df['return_status_numeric'].mean() * 100\n",
    "    print(f\"Overall Return Rate: {return_rate:.2f}%\")\n",
    "    \n",
    "    if 'category' in df.columns:\n",
    "        sns.barplot(x='category', y='return_status_numeric', data=df)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.title(\"Return Rate by Category\")\n",
    "        plt.savefig(\"outputs/return_rate_by_category.png\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# Question 13: Brand Performance\n",
    "# ----------------------\n",
    "def brand_performance(df):\n",
    "    brand_share = df.groupby('brand')['revenue'].sum().reset_index()\n",
    "    brand_share.sort_values('revenue', ascending=False).head(15).plot(kind='bar', x='brand', y='revenue')\n",
    "    plt.title(\"Top 15 Brands by Revenue\")\n",
    "    plt.savefig(\"outputs/top_brands.png\")\n",
    "    plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Question 14: CLV Analysis\n",
    "# ----------------------\n",
    "def clv_analysis(df):\n",
    "    cohort = df.groupby(['customer_id', df['order_date'].dt.to_period('M')])['revenue'].sum().reset_index()\n",
    "    cohort['cohort'] = cohort.groupby('customer_id')['order_date'].transform('min')\n",
    "    cohort.to_csv(\"outputs/clv_cohort.csv\", index=False)\n",
    "\n",
    "# ----------------------\n",
    "# Question 15: Discount Effectiveness\n",
    "# ----------------------\n",
    "def discount_effectiveness(df):\n",
    "    sns.scatterplot(x='discount_percent', y='revenue', data=df)\n",
    "    plt.title(\"Discount % vs Revenue\")\n",
    "    plt.savefig(\"outputs/discount_vs_revenue.png\")\n",
    "    plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Question 16: Product Ratings Impact\n",
    "# ----------------------\n",
    "def rating_impact(df):\n",
    "    sns.boxplot(x='customer_rating', y='revenue', data=df)\n",
    "    plt.title(\"Revenue by Product Rating\")\n",
    "    plt.savefig(\"outputs/rating_vs_revenue.png\")\n",
    "    plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Question 17: Customer Journey\n",
    "# ----------------------\n",
    "def customer_journey(df):\n",
    "    journey = df.groupby(['customer_id', 'category'])['order_id'].count().unstack(fill_value=0)\n",
    "    journey.to_csv(\"outputs/customer_journey_matrix.csv\")\n",
    "\n",
    "# ----------------------\n",
    "# Question 18: Inventory Lifecycle\n",
    "# ----------------------\n",
    "def inventory_lifecycle(df):\n",
    "    prod_life = df.groupby(['product_id'])['order_date'].agg(['min','max']).reset_index()\n",
    "    prod_life['lifecycle_days'] = (prod_life['max'] - prod_life['min']).dt.days\n",
    "    prod_life.to_csv(\"outputs/product_lifecycle.csv\", index=False)\n",
    "\n",
    "# ----------------------\n",
    "# Question 19: Competitive Pricing\n",
    "# ----------------------\n",
    "def competitive_pricing(df):\n",
    "    sns.boxplot(x='brand', y='subtotal_inr', data=df)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"Brand Price Comparison\")\n",
    "    plt.savefig(\"outputs/brand_price_comparison.png\")\n",
    "    plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Question 20: Business Health Dashboard\n",
    "# ----------------------\n",
    "def business_health_dashboard(df):\n",
    "    metrics = {\n",
    "        'total_revenue': df['revenue'].sum(),\n",
    "        'unique_customers': df['customer_id'].nunique(),\n",
    "        'total_orders': df['order_id'].nunique()\n",
    "    }\n",
    "    pd.DataFrame([metrics]).to_csv(\"outputs/business_health_summary.csv\", index=False)\n",
    "\n",
    "# ----------------------\n",
    "# Main Execution\n",
    "# ----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    data_dir = \"../dataset\"  # update as needed\n",
    "    data = load_amazon_data(data_dir)\n",
    "    revenue_trend_analysis(data)\n",
    "    seasonal_pattern_analysis(data)\n",
    "    rfm_customer_segmentation(data)\n",
    "    payment_method_evolution(data)\n",
    "    category_performance(data)\n",
    "    prime_impact(data)\n",
    "    geographic_analysis(data)\n",
    "    festival_impact(data, {\"Diwali\": {\"start\": \"2025-10-15\", \"end\": \"2025-11-15\"}})\n",
    "    age_group_behavior(data)\n",
    "    price_vs_demand(data)\n",
    "    delivery_performance(data)\n",
    "    return_patterns(data)\n",
    "    brand_performance(data)\n",
    "    clv_analysis(data)\n",
    "    discount_effectiveness(data)\n",
    "    rating_impact(data)\n",
    "    customer_journey(data)\n",
    "    inventory_lifecycle(data)\n",
    "    competitive_pricing(data)\n",
    "    business_health_dashboard(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c526ba7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['order_id', 'order_date', 'customer_id', 'product_id', 'product_name',\n",
       "       'category', 'subcategory', 'brand', 'original_price_inr',\n",
       "       'discount_percent', 'discounted_price_inr', 'quantity', 'subtotal_inr',\n",
       "       'delivery_charges', 'revenue', 'customer_city', 'customer_state',\n",
       "       'customer_tier', 'customer_spending_tier', 'customer_age_group',\n",
       "       'payment_method', 'delivery_days', 'delivery_type', 'prime_member',\n",
       "       'is_festival_sale', 'festival_name', 'customer_rating', 'return_status',\n",
       "       'order_month', 'order_year', 'order_quarter', 'product_weight_kg',\n",
       "       'is_prime_eligible', 'product_rating', 'year', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585fdfc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
